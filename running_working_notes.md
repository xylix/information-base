
## 19.03.2025


initial attempts at categorizing a small amount of links with an LLM.

    ([idea]: could use DSPY or another prompt-improvement tool, by building some good example manually and then optimizing on them)



prompt - response pairs:

```fish
 ~> ollama run gemma3:12b 'Give one of the following categories for each link that follows, or suggest a new category.
    categories: [self-improvement, relationships, university courses, scientific research, artificial intelligence, job searches]
    https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=email&utm_term=0_f2e9d15594-b71c1a1f3d-136469184&mc_cid=db6603dc11
    https://www.reddit.com/r/mtgvorthos/comments/uhi1sv/a_garden_of_flesh/
    https://magic.wizards.com/en/news/magic-story/garden-flesh-2022-05-03
    https://mindingourway.com/self-compassion/
    https://loveuncommon.com/2017/09/28/self-consent/
    https://www.lesswrong.com/posts/BfTW9jmDzujYkhjAb/loving-yourself-1#Nick_thinks_that_the_two_most_promising_avenues_are_solo_MDMA_trips_and_metta__lovingkindness__meditation_
    https://meaningness.substack.com/p/you-should-be-a-god-emperor
    https://kajsotala.fi/2023/02/in-defense-of-chatbot-romance/
    https://gwern.net/llm-writing
    '
Here's a breakdown of the links with assigned categories:

*   **https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_mediu**https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=email&utm_term=0_f2e9d15594-b71c1a1f3d-136469184&mc_cid=db6603dc11** - **Relationships** (Focuses on building and maintaining friendships)
*   **https://www.reddit.com/r/mtgvorthos/comments/uhi1sv/a_garden_flesh/** - *New Category: **Hobbies/Gaming** (Specifically, Magic: The Gathering)* (This is a discussion on a specific card and lore within a
game.)
*   **https://magic.wizards.com/en/news/magic-story/garden-flesh-2022-05-03** - *New Category: **Hobbies/Gaming** (Specifically, Magic: The Gathering)* (Related to the previous link, it's about the same
game's story.)
*   **https://mindingourway.com/self-compassion/** - **Self-improvement** (Deals with a key aspect of personal growth)
*   **https://loveuncommon.com/2017/09/28/self-consent/** - **Relationships** (Explores a concept relevant to healthy relationships and boundaries)
*   **https://www.leswrong.com/posts/BfTW9jmDzujYkhjAb/loving-yourself-1#Nick_thinks_that_the_two_most_promising_avenues_are_solo_MDMA_trips_and_metta__lovingkindness__meditation_** - **Self-improvement**
(Focuses on methods for self-love and personal growth)
*   **https://meaningness.substack.com/p/you-should-be-a-god-emperor** - *New Category: **Philosophy/Speculative Thought** (This is a thought experiment and philosophical discussion)*
*   **https://kajsotala.fi/2023/02/in-defense-of-chatbot-romance/** - **Artificial Intelligence** (Discusses the emerging phenomenon of relationships with AI chatbots)
*   **https://gwern.net/llm-writing** - **Artificial Intelligence** (Focuses on writing generated by Large Language Models)



I've added a few new categories to better accommodate the content of some of the links.

 ~> ollama run gemma3:12b 'Give one of the following categories for each link that follows, or suggest a new category. Output a list of lines, that only contains the link, and then the relevant category. At the end output a list of new categories.
    Initial categories: [self-improvement, relationships, university courses, scientific research, artificial intelligence, job searches]
    Links:
    https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=email&utm_term=0_f2e9d15594-b71c1a1f3d-136469184&mc_cid=db6603dc11
    https://www.reddit.com/r/mtgvorthos/comments/uhi1sv/a_garden_of_flesh/
    https://magic.wizards.com/en/news/magic-story/garden-flesh-2022-05-03
    https://mindingourway.com/self-compassion/
    https://loveuncommon.com/2017/09/28/self-consent/
    https://www.lesswrong.com/posts/BfTW9jmDzujYkhjAb/loving-yourself-1#Nick_thinks_that_the_two_most_promising_avenues_are_solo_MDMA_trips_and_metta__lovingkindness__meditation_
    https://meaningness.substack.com/p/you-should-be-a-god-emperor
    https://kajsotala.fi/2023/02/in-defense-of-chatbot-romance/
    https://gwern.net/llm-writing
    '
Here's the categorized list of links, followed by suggested new categories:

https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=emaicategories:https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=email&utm_term=0_f2e9d15594-b71c1a1f3d-136469184&mc_cid=db6603dc11 - relationships
https://www.reddit.com/r/mtgvorthos/comments/uhi1sv/a_garden_flesh/ - hobbies
https://magic.wizards.com/en/news/magic-story/garden-flesh-2022-05-03 - hobbies
https://mindingourway.com/self-compassion/ - self-improvement
https://loveuncommon.com/2017/09/28/self-consent/ - relationships
https://www.leswrong.com/posts/BfTW9jmDzujYkhjAb/loving-yourself-1#Nick_thinks_that_the_two_most_promising_avenues_are_solo_MDMA_trips_and_metta__lovingkindness__meditation_ - self-improvement
https://meaningness.substack.com/p/you-should-be-a-god-emperor - artificial intelligence
https://kajsotala.fi/2023/02/in-defense-of-chatbot-romance/ - artificial intelligence
https://gwern.net/llm-writing - artificial intelligence

**Suggested New Categories:**

*   **Hobbies:** For links related to recreational activities and interests.
*   **Gaming:** For links related to games.

 ~> ollama run gemma3:12b 'Give one of the following categories for each link that follows, or suggest a new category. Output a list of lines, that only contains the link, and then the relevant category. At the end output a list of new categories.
    Initial categories: [self-improvement, relationships, university courses, scientific research, artificial intelligence, job searches, magic the gathering]
    Links:
    https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=email&utm_term=0_f2e9d15594-b71c1a1f3d-136469184&mc_cid=db6603dc11
    https://www.reddit.com/r/mtgvorthos/comments/uhi1sv/a_garden_of_flesh/
    https://magic.wizards.com/en/news/magic-story/garden-flesh-2022-05-03
    https://mindingourway.com/self-compassion/
    https://loveuncommon.com/2017/09/28/self-consent/
    https://www.lesswrong.com/posts/BfTW9jmDzujYkhjAb/loving-yourself-1#Nick_thinks_that_the_two_most_promising_avenues_are_solo_MDMA_trips_and_metta__lovingkindness__meditation_
    https://meaningness.substack.com/p/you-should-be-a-god-emperor
    https://kajsotala.fi/2023/02/in-defense-of-chatbot-romance/
    https://gwern.net/llm-writing
    '
Here's the categorized list of links, followed by suggested new categories:

https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=emaicategories:https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=email&utm_term=0_f2e9d15594-b71c1a1f3d-136469184&mc_cid=db6603dc11 - relationships
https://www.reddit.com/r/mtgvorthos/comments/uhi1sv/a_garden_flesh/ - magic the gathering
https://magic.wizards.com/en/news/magic-story/garden-flesh-2022-05-03 - magic the gathering
https://mindingourway.com/self-compassion/ - self-improvement
https://loveuncommon.com/2017/09/28/self-consent/ - self-improvement
https://www.leswrong.com/posts/BfTW9jmDzujYkhjAb/loving-yourself-1#Nick_thinks_that_the_two_most_promising_avenues_are_solo_MDMA_trips_and_metta__lovingkindness__meditation_ - self-improvement
https://meaningness.substack.com/p/you-should-be-a-god-emperor - artificial intelligence
https://kajsotala.fi/2023/02/in-defense-of-chatbot-romance/ - artificial intelligence
https://gwern.net/llm-writing - artificial intelligence

**Suggested New Categories:**

*   **Philosophy/Rationality:** (Could encompass some of the "self-improvement" links, but with a more philosophical bent)
*   **Chatbots/AI Romance:** (A more specific category for the chatbot romance links)
*   **Digital Culture:** (Could be used for links discussing online trends and behaviors)

 ~> ollama run gemma3:12b 'Give one of the following categories for each link that follows, or suggest a new category (only if necessary). Output a list of lines, that only contains the link, and then the relevant category. At the end output a list of new categories as a JSON list. An arrow -> signifies a subcategory.
    Initial categories: [self-improvement, relationships, university courses, university courses -> math, university courses -> computer science, scientific research, artificial intelligence, job searches rationality, rationality->slatestarcodex, effective altruism]
    Links:
    https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=email&utm_term=0_f2e9d15594-b71c1a1f3d-136469184&mc_cid=db6603dc11
    https://www.reddit.com/r/mtgvorthos/comments/uhi1sv/a_garden_of_flesh/
    https://magic.wizards.com/en/news/magic-story/garden-flesh-2022-05-03
    https://mindingourway.com/self-compassion/
    https://loveuncommon.com/2017/09/28/self-consent/
    https://www.lesswrong.com/posts/BfTW9jmDzujYkhjAb/loving-yourself-1#Nick_thinks_that_the_two_most_promising_avenues_are_solo_MDMA_trips_and_metta__lovingkindness__meditation_
    https://meaningness.substack.com/p/you-should-be-a-god-emperor
    https://kajsotala.fi/2023/02/in-defense-of-chatbot-romance/
    https://gwern.net/llm-writing
    '
https://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=emaihttps://www.clearerthinking.org/post/a-guide-on-building-lasting-connections-how-to-make-and-keep-friends?utm_source=ClearerThinking.org&utm_campaign=db6603dc11-EMAIL_CAMPAIGN_HAPPINESS_COPY_01&utm_medium=email&utm_term=0_f2e9d15594-b71c1a1f3d-136469184&mc_cid=db6603dc11 relationships
https://www.reddit.com/r/mtgvorthos/comments/uhi1sv/a_garden_flesh/ job searches rationality
https://magic.wizards.com/en/news/magic-story/garden-flesh-2022-05-03 job searches rationality
https://mindingourway.com/self-compassion/ self-improvement
https://loveuncommon.com/2017/09/28/self-consent/ self-improvement
https://www.leswrong.com/posts/BfTW9jmDzujYkhjAb/loving-yourself-1#Nick_thinks_that_the_two_most_promising_avenues_are_solo_MDMA_trips_and_metta__lovingkindness__meditation_ self-improvement
https://meaningness.substack.com/p/you-should-be-a-god-emperer artificial intelligence
https://kajsotala.fi/2023/02/in-defense-of-chatbot-romance/ artificial intelligence
https://gwern.net/llm-writing artificial intelligence

```json
[
  "job searches rationality -> mtg",
  "artificial intelligence -> chatbot romance"
]
```

Observations:
    - When I tried adding the suggested categories to the prompt, AI invents new categories
    - When I added the arrows, and many categories, it gets confused about MTG. Since there is no data for "job searches rationality" I guess it tries to allocate something to that anyway? Or something?


Running log:
    - I want to batch run a few hundred links, in sets of dozens, and then get the category lists that the AI outputs, make a coherent list from them as a human, and then use that category list for a proper categorization run and see what comes out.
    - brr coding
    - running the script url_processor.py for ~300 links.
    - Notice it gets stuck at batch 310.
    - There are long query parameters for some google searches there, I'll filter these out manually (if this happens in the future often maybe regex it)
        https://www.google.com/search?q=how+was+le+chat+built&num=10&client=firefox-b-d&sca_esv=aa4709d8f74669be&sxsrf=AHTn8zrT4_-B6Eu3dB1L2BWCZR9ZCnu0hA%3A1739209996028&ei=DD2qZ-eeAc3NwPAP4ZXjuAM&ved=0ahUKEwjn1IKQ1rmLAxXNJhAIHeHKGDcQ4dUDCBE&uact=5&oq=how+was+le+chat+built&gs_lp=Egxnd3Mtd2l6LXNlcnAiFWhvdyB3YXMgbGUgY2hhdCBidWlsdDIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYR0iwC1DqAVjCCnACeAGQAQGYAYsBoAHIBKoBAzIuNLgBA8gBAPgBAZgCB6AC7APCAgUQIRigAcICBBAhGBXCAgcQIxiwAhgnwgIIEAAYgAQYogTCAgUQABjvBcICBBAjGCeYAwDiAwUSATEgQIgGAZAGCJIHAzQuM6AH7xk&sclient=gws-wiz-serp
        https://www.google.com/search?q=kolmas+sukupuolimerkint%C3%A4+lakialoite&num=10&client=firefox-b-d&sca_esv=aa4709d8f74669be&sxsrf=AHTn8zoDh2jPyh1glmwBqGoOzFnvM7BNlg%3A1739210022914&ei=Jj2qZ_m8N-WHwPAPlr6_oQo&ved=0ahUKEwj55-uc1rmLAxXlAxAIHRbfL6QQ4dUDCBE&uact=5&oq=kolmas+sukupuolimerkint%C3%A4+lakialoite&gs_lp=Egxnd3Mtd2l6LXNlcnAiJGtvbG1hcyBzdWt1cHVvbGltZXJraW50w6QgbGFraWFsb2l0ZTIFEAAY7wUyBRAAGO8FMgUQABjvBUjTF1AWWPAWcAN4AZABAJgBY6ABrAaqAQIxMbgBA8gBAPgBAZgCDqAC0AbCAgoQABiwAxjWBBhHwgIGEAAYFhgewgIIEAAYgAQYogTCAgUQIRigAcICBxAhGKABGAqYAwCIBgGQBgKSBwQxMi4yoAeLIw&sclient=gws-wiz-serp
    - Used this vim search pattern written by Claude to find long lines `/\v.{150,}` and manually deleted some ?share-id params for reddit and linkedin links and then various metadata for google links. (Estimate was that long google links around line 310 were breaking the LLM because my local LLM probably has a small context window.)
    - Now it's running better again,
    - Raw list of new categories that the initial first full run generated:,
        - ["societal_analysis", job_searches, artifial_intelligence, aviation, programming, careers, business, tech_careers, finland_specific_services, "Finnish news", media_criticism, politics, game_development, political_analysis, "political_forecasting", "self_hosting", "technology_news", "LLM_tools", "cybersecurity", "AI governance", "distributed_computing", "decision_making", sexuality "government_policy" "gaming_strategy", "news", "gaming", "economics", "medical_tests", "cryptocurrency_economics", "computer_science", "university_courses", "politics","relationships", "government_publications", "Data and APIs", "AI Safety", "AI in Games", "data_processing", "vector_databases", "machine_learning_tools"]
    - Could be useful to sort the URLs. Either so that ones from same domain are close to each other (would increase odds that they get the same category) or randomized (would probably even out the distribution).
    - Extracted google notes with claude written google_url_to_note_converter.py:
        - ```cat start_data.txt | python google_url_to_note_converter.py > google_url_processed_notes.txt```
        - opened start_data.txt in vim and run `:g/google.com\/search/d` to delete all google lines

Observed behaviour:
    - As mentioned above, using -> for subcategories confused the program.
    - Current script ometimes adds a new category but doesn't actually categorize any links to the category.
    - And sometimes it marks very confused categories: It understands that  "https://www.google.com/search?client=firefox-b-d&q=marco+rubio+elon+musk+argument" is of Topic "political debate search" but it categorizes it as "self_improvement"

Ideas for improving:
    - Optimize prompt, try different ollama modes (chat vs. prompt vs. generate), try ollama.cpp and temperature etc settings
    - Category ideas:
        - "Todos", somehow explain that many google links are todos
        - yhteiskuntatiede (social sciences)? separated for general, finland, us, eu levels?
        - history
        - "unknown"
    - Automoitu tarkistus että mikään URL ei hallusinoitunut prosessista?
        - Nopealla (Claude written) scriptillä näyttää että ~62 urlia puuttuisi output.txt:stä. Mutta tähän sisältyy myös
    - Use scripting + LLM to enrichen the data (add URL titles, fix quote blocks)


## 22.03.2025 commit polisher work

- Now it's running! See code at commit_message_polisher.py + the one-liner server script at llama_commit_backend.sh
- It's processing at ~5-20 seconds per query (around 12 tokens / sec with each query taking ~100ish tokens + small amount of time for overhead and prompt processing
- could try batch processing?
    - would need async post requests hmm
    - Running some llama benchmarks
        - Damn these tools are handy

```txt
llama-batched-bench -m Code/models/gemma-3-12b-it-Q8_0.gguf -c 16384 -b 2048 -npp 1024 -ntg 128 -npl 1,2,4,5,6,8 -ngl 50

...
<output noise>
...

main: n_kv_max = 16384, n_batch = 2048, n_ubatch = 512, flash_attn = 0, is_pp_shared = 0, n_gpu_layers = 50, n_threads = 8, n_threads_batch = 8

|    PP |     TG |    B |   N_KV |   T_PP s | S_PP t/s |   T_TG s | S_TG t/s |      T s |    S t/s |
|-------|--------|------|--------|----------|----------|----------|----------|----------|----------|
|  1024 |    128 |    1 |   1152 |    6.612 |   154.88 |   10.552 |    12.13 |   17.163 |    67.12 |
|  1024 |    128 |    2 |   2304 |   12.049 |   169.97 |   14.233 |    17.99 |   26.282 |    87.66 |
|  1024 |    128 |    4 |   4608 |   25.123 |   163.04 |   19.143 |    26.75 |   44.266 |   104.10 |
|  1024 |    128 |    5 |   5760 |   32.141 |   159.30 |   21.072 |    30.37 |   53.213 |   108.24 |
|  1024 |    128 |    6 |   6912 |   39.492 |   155.57 |   28.127 |    27.30 |   67.620 |   102.22 |
|  1024 |    128 |    8 |   9216 |   55.298 |   148.14 |   35.183 |    29.10 |   90.481 |   101.86 |

llama_perf_context_print:        load time =    1651.64 ms
llama_perf_context_print: prompt eval time =  287669.71 ms / 29840 tokens (    9.64 ms per token,   103.73 tokens per second)
llama_perf_context_print:        eval time =   10551.62 ms /   128 runs   (   82.43 ms per token,    12.13 tokens per second)
llama_perf_context_print:       total time =  300677.16 ms / 29968 tokens
ggml_metal_free: deallocating
```

Figured out: 
- gpu layer size doesn't seem to change anything as long as it's not set very low (the default of -1 seems to mean the tool will automatically figure out a sensible layer amount to put in vram)
    - With gpu layer size 10-25 the benchmark didn't print anything for minutes, so it's ~3-10x slower with those values
- batch size of 5 seems to have optimal results with this model and machine
    - 8 batch size + 16k context was close to my machines RAM limit with this 12bQ8 model., so its good that I don't need to use 8 or higher
    - Batch size 5 is a ~50% performance improvement, relevant, but plausibly not useful enough to justify significant programming time. If the task takes hours to run anyway 50% doens't make a big difference.
        - A couple 50% increases would

- regarding performance:
    - With current speed and my repo having ~2700 commits, with around 1500 non-autosave commits, and 1200 autosave commits (I should somehow combine those before llm commit message processing, for example squash every hour of autosave commits into one)
        - It's doing a couple hundred per hour. (Taking around ~10 seconds each, so theoretically should be able to do 360 per hour, but my script is probably not keeping the backend satisfied all the time)
        - mmm i could actually just run a separate script at the same time starting from the last 1200 commits
            - [x] did this from commit 1000-onwards
                - still want to figure out what to do with autosave commits
    - As said above batching could achieve a ~50% performance improvement, but utilizing it well would add code complexity
        - There should also be a ~10-20% gain from making async code from being able to keep the backend processing all the time
            - But could also grab this by just running another script

    - Tool for estimating .gguf model memory usage (can set context size etc as a parameter)
        - https://github.com/gpustack/gguf-parser-go/tree/main/cmd/gguf-parser
        - observation from running gguf-parser-darwin-arm64 -m Code/models/gemma-3-12b-it-Q8_0.gguf --ctx-size <8000, 16000>: Model VRAM usage seems linearly correlated with context size when other parameters are unchanged

    - Community benchmark results for llama.cpp on apple m series hardware https://github.com/ggml-org/llama.cpp/discussions/4167

- regarding context size:
    - A large git commit (60kb) `git --no-pager diff 219afe49c4cf4015ae67754b8faf791692418fe5 219afe49c4cf4015ae67754b8faf791692418fe5^` becomes around 25 000 tokens
        - 60000 characters -> 25k tokens
        - So if I use a 16k context window it should be able to fit ~30k chracters nicely?
            - 16k seemed a bit large when using the server (memory pressure went into yello) so trying 3*4096 = 12k context window size (and 22k characters limit

- So I increased parallelism to 2 in same time, but also increased context size -> it's running slower now 

- ran passes with commit_description_refiner. I now have a file of 1400 commit hashes and the AIs best suggestions for commit messages
- 


## 24.03.2025

- output files output_3 today

- gemma-3 benchmarking:
    - Should improve quality: Now using recommended temperature, top-k and top-p
with 1b 8q drafting model
    - with drafting model `llama-server --grammar-file ~/Code/information_base_proto/commit_suggestion_schema.gbnf -m ~/Code/models/gemma-3-12b-it-Q8_0.gguf -c 12288 --temp 1.0 --top-k 64 --top-p 0.95 -n 128 -np 2`

run of 12 commits:

iteration 1 time: 7.277379989624023. Spent in LLM request: 7.277112007141113
iteration 2 time: 8.883140087127686. Spent in LLM request: 8.882775068283081
iteration 3 time: 8.687573194503784. Spent in LLM request: 8.687138080596924
iteration 4 time: 6.933151960372925. Spent in LLM request: 6.932924270629883
iteration 5 time: 9.034284830093384. Spent in LLM request: 9.033998012542725
iteration 6 time: 9.546880006790161. Spent in LLM request: 9.546646118164062
iteration 7 time: 8.565376043319702. Spent in LLM request: 8.565117835998535
iteration 8 time: 5.854483127593994. Spent in LLM request: 5.854053020477295
iteration 9 time: 7.975300073623657. Spent in LLM request: 7.975009918212891
iteration 10 time: 9.342612028121948. Spent in LLM request: 9.342353820800781
iteration 11 time: 9.418689966201782. Spent in LLM request: 9.418364763259888
iteration 12 time: 7.933442831039429. Spent in LLM request: 7.9319541454315186

second run (more RAM free)

iteration 1 time: 7.749130010604858. Spent in LLM request: 7.748865842819214
iteration 2 time: 8.538575887680054. Spent in LLM request: 8.538130044937134
iteration 3 time: 6.2677130699157715. Spent in LLM request: 6.267401218414307
iteration 4 time: 8.21058988571167. Spent in LLM request: 8.210214138031006
iteration 5 time: 9.621405839920044. Spent in LLM request: 9.62113094329834
iteration 6 time: 11.124515771865845. Spent in LLM request: 11.122999906539917
iteration 7 time: 8.456011056900024. Spent in LLM request: 8.455771923065186
iteration 8 time: 7.025587320327759. Spent in LLM request: 7.025300025939941
iteration 9 time: 7.2640540599823. Spent in LLM request: 7.263823986053467
iteration 10 time: 9.588106870651245. Spent in LLM request: 9.587868213653564
iteration 11 time: 7.726407766342163. Spent in LLM request: 7.726181268692017
iteration 12 time: 8.182787895202637. Spent in LLM request: 8.182549953460693

running 20 tasks total time: 169.09207606315613


    - without drafting model 
run of 12 commits

iteration 1 time: 8.7862389087677. Spent in LLM request: 8.785879135131836
iteration 2 time: 8.629988670349121. Spent in LLM request: 8.629764080047607
iteration 3 time: 7.063875198364258. Spent in LLM request: 7.063704013824463
iteration 4 time: 8.421253204345703. Spent in LLM request: 8.421022891998291
iteration 5 time: 9.377028226852417. Spent in LLM request: 9.376824140548706
iteration 6 time: 10.671042919158936. Spent in LLM request: 10.670779705047607
iteration 7 time: 8.33873200416565. Spent in LLM request: 8.338506937026978
iteration 8 time: 6.014728307723999. Spent in LLM request: 6.014522075653076
iteration 9 time: 7.5089499950408936. Spent in LLM request: 7.508731365203857
iteration 10 time: 8.266093969345093. Spent in LLM request: 8.265892267227173
iteration 11 time: 6.920624256134033. Spent in LLM request: 6.920413970947266
iteration 12 time: 9.047682046890259. Spent in LLM request: 9.047457695007324

running 20 tasks total time 166.78280568122864


--
LLM performance todos:
    - benchmark gemma-3 with draft model and no draft model with different context sizes and prompts
        - above some benchmarks, also changed temperature, top_k, top_p etc
        - Could try different sized draft models? Like 4b? But people claim 10x difference (which 12b and 1b ~gets) is usually optimal.
        - recommended settings: https://www.reddit.com/r/LocalLLaMA/comments/1j9hsfc/gemma_3_ggufs_recommended_settings/ , https://huggingface.co/unsloth/gemma-3-27b-it-GGUF/blob/main/params
            - temperature = 1.0, top_k = 64, top_p = 0.95, min_p = 0.01, repeat_penalty = 1.0
    - add correct instructions to gemma-3 code in this repo https://huggingface.co/unsloth/gemma-3-1b-it-GGUF
        - <bos><start_of_turn>user
        knock knock<end_of_turn>
        <start_of_turn>model
        - Pitää sallia modelin kirjoittaa end_of_turn token promptin lopussa, ja llama.cpp lisää itsestään <bos> tokenin
        - Testailua:
            - Description refiner testi ilmankin end_of_turnin sallimista, se että promptiin lisäs noi start user / end user turn ja start of turn model se nopeutui huomattavasti. N. 50%
            - Commit generatorille testi: Ilman instructioneja, n. 10 sec / 1000 tokeniin promptiin vastaaminen. N. ~11-11.5 tokens / s
            - Huh, description-yhdistin steppi ylikäyttää sanaa "Clever" tosi lujaa. Se ei löydy niistä pohjakuvauksista. Ehkä joku temperature tai muu säätö toimis?
                - "Avoid unnecessary adjectives" paransi tätä
            - Nyt se hallusinoi Tänne jotain random tiiminjäseniä.
            - Mun promptin "try to keep names if at all possible" oli ehkä se mikä hämmensi. Muutin promptia.
    - vois kokeilla kuvantunnistusta esim. ShieldGemma2:sella?
    - speculativde decoding stuff:
        - https://github.com/ggml-org/llama.cpp/discussions/10466

Prompt optimizing ideas:
    - https://github.com/SylphAI-Inc/AdalFlow
        - > Say goodbye to manual prompting: AdalFlow provides a unified auto-differentiative framework for both zero-shot optimization and few-shot prompt optimization. Our research, LLM-AutoDiff and Learn-to-Reason Few-shot In Context Learning, achieve the highest accuracy among all auto-prompt optimization libraries.
    - DSPY https://github.com/stanfordnlp/dspy
        - DSPy: Programming—not prompting—Foundation Models


-- trying to run models with apple neural engine.
- MLX format stuff:

    - (drafted message to generative ais group, didn't end up sending yet because experiment isn't done):
    re Apple Neural models:

    came across this thread recently https://www.reddit.com/r/LocalLLaMA/comments/1fz6z79/lm_studio_ships_an_mlx_backend_run_any_llm_from/ where people are using lm-studio, and getting 0-50% gains (with Qwen 2.5 variants, different hardware for different gains).

    And also came across some tech that lets one run models from huggingface with the neural engine in libraries.


    - See 
        - /Users/xylix/Code/machine_learning/mlx_experiments
            - fastmlx
            - mlx-lm mlx vlm
        links:
            - https://github.com/arcee-ai/fastmlx?tab=readme-ov-file
            - mlx-community on huggingface:
                - https://huggingface.co/collections/mlx-community/gemma-3-67d14a10480a436ad478b0f9
                - Missä on kaikki benchmarkit jossa verrataan samaa mlx mallia saman mallin ggufiin samalla raudalla?

        - LM Studio joka tukee MLX malleja https://www.reddit.com/r/LocalLLaMA/comments/1fz6z79/lm_studio_ships_an_mlx_backend_run_any_llm_from/ 
            - Reddit threadissa porukan gainit jotain 10-50% eri malleilla ja eri mäkeillä
                - Ja VRAM savings kun toimii oikein
            - Väitetysti MLX:llä mallit toimii paremmin isolla kontekstilla? Jotain jotain applen AI magic?
    - 
